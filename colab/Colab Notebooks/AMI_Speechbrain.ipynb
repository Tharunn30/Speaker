{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1v999HiueXrQCAGKRw-mbjR2DL_0_MfDV","authorship_tag":"ABX9TyMDLnV3VwMSXSw3N5kfq7qm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"id":"oFH1hgfBksPW","executionInfo":{"status":"error","timestamp":1693502119969,"user_tz":-330,"elapsed":3376,"user":{"displayName":"Sherin Shibi","userId":"05792894419737785934"}},"outputId":"c9fdf245-6164-4a15-d89c-bea64ad0a975"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-3990b17ac5e5>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mami_splits\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_AMI_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m from speechbrain.dataio.dataio import (\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mload_pkl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msave_pkl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'speechbrain'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["\"\"\"\n","Data preparation.\n","\n","Download: http://groups.inf.ed.ac.uk/ami/download/\n","\n","Prepares metadata files (JSON) from manual annotations \"segments/\" using RTTM format (Oracle VAD).\n","\"\"\"\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir('/content/drive/MyDrive/Colab Notebooks')\n","\n","import logging\n","import xml.etree.ElementTree as et\n","import glob\n","import json\n","from ami_splits import get_AMI_split\n","\n","from speechbrain.dataio.dataio import (\n","    load_pkl,\n","    save_pkl,\n",")\n","\n","logger = logging.getLogger(__name__)\n","SAMPLERATE = 16000\n","\n","\n","def prepare_ami(\n","    data_folder,\n","    manual_annot_folder,\n","    save_folder,\n","    ref_rttm_dir,\n","    meta_data_dir,\n","    split_type=\"full_corpus_asr\",\n","    skip_TNO=True,\n","    mic_type=\"Lapel\",\n","    vad_type=\"oracle\",\n","    max_subseg_dur=3.0,\n","    overlap=1.5,\n","):\n","    \"\"\"\n","    Prepares reference RTTM and JSON files for the AMI dataset.\n","\n","    Arguments\n","    ---------\n","    data_folder : str\n","        Path to the folder where the original amicorpus is stored.\n","    manual_annot_folder : str\n","        Directory where the manual annotations are stored.\n","    save_folder : str\n","        The save directory in results.\n","    ref_rttm_dir : str\n","        Directory to store reference RTTM files.\n","    meta_data_dir : str\n","        Directory to store the meta data (json) files.\n","    split_type : str\n","        Standard dataset split. See ami_splits.py for more information.\n","        Allowed split_type: \"scenario_only\", \"full_corpus\" or \"full_corpus_asr\"\n","    skip_TNO: bool\n","        Skips TNO meeting recordings if True.\n","    mic_type : str\n","        Type of microphone to be used.\n","    vad_type : str\n","        Type of VAD. Kept for future when VAD will be added.\n","    max_subseg_dur : float\n","        Duration in seconds of a subsegments to be prepared from larger segments.\n","    overlap : float\n","        Overlap duration in seconds between adjacent subsegments\n","\n","    Example\n","    -------\n","    >>> from recipes.AMI.ami_prepare import prepare_ami\n","    >>> data_folder = '/network/datasets/ami/amicorpus/'\n","    >>> manual_annot_folder = '/home/mila/d/dawalatn/nauman/ami_public_manual/'\n","    >>> save_folder = 'results/save/'\n","    >>> split_type = 'full_corpus_asr'\n","    >>> mic_type = 'Lapel'\n","    >>> prepare_ami(data_folder, manual_annot_folder, save_folder, split_type, mic_type)\n","    \"\"\"\n","\n","    # Meta files\n","    meta_files = [\n","        os.path.join(meta_data_dir, \"ami_train.\" + mic_type + \".subsegs.json\"),\n","        os.path.join(meta_data_dir, \"ami_dev.\" + mic_type + \".subsegs.json\"),\n","        os.path.join(meta_data_dir, \"ami_eval.\" + mic_type + \".subsegs.json\"),\n","    ]\n","\n","    # Create configuration for easily skipping data_preparation stage\n","    conf = {\n","        \"data_folder\": data_folder,\n","        \"save_folder\": save_folder,\n","        \"ref_rttm_dir\": ref_rttm_dir,\n","        \"meta_data_dir\": meta_data_dir,\n","        \"split_type\": split_type,\n","        \"skip_TNO\": skip_TNO,\n","        \"mic_type\": mic_type,\n","        \"vad\": vad_type,\n","        \"max_subseg_dur\": max_subseg_dur,\n","        \"overlap\": overlap,\n","        \"meta_files\": meta_files,\n","    }\n","\n","    if not os.path.exists(save_folder):\n","        os.makedirs(save_folder)\n","\n","    # Setting output option files.\n","    opt_file = \"opt_ami_prepare.\" + mic_type + \".pkl\"\n","\n","    # Check if this phase is already done (if so, skip it)\n","    if skip(save_folder, conf, meta_files, opt_file):\n","        logger.info(\n","            \"Skipping data preparation, as it was completed in previous run.\"\n","        )\n","        return\n","\n","    msg = \"\\tCreating meta-data file for the AMI Dataset..\"\n","    logger.debug(msg)\n","\n","    # Get the split\n","    train_set, dev_set, eval_set = get_AMI_split(split_type)\n","\n","    # Prepare RTTM from XML(manual annot) and store are groundtruth\n","    # Create ref_RTTM directory\n","    if not os.path.exists(ref_rttm_dir):\n","        os.makedirs(ref_rttm_dir)\n","\n","    # Create reference RTTM files\n","    splits = [\"train\", \"dev\", \"eval\"]\n","    for i in splits:\n","        rttm_file = ref_rttm_dir + \"/fullref_ami_\" + i + \".rttm\"\n","        if i == \"train\":\n","            prepare_segs_for_RTTM(\n","                train_set,\n","                rttm_file,\n","                data_folder,\n","                manual_annot_folder,\n","                i,\n","                skip_TNO,\n","            )\n","        if i == \"dev\":\n","            prepare_segs_for_RTTM(\n","                dev_set,\n","                rttm_file,\n","                data_folder,\n","                manual_annot_folder,\n","                i,\n","                skip_TNO,\n","            )\n","        if i == \"eval\":\n","            prepare_segs_for_RTTM(\n","                eval_set,\n","                rttm_file,\n","                data_folder,\n","                manual_annot_folder,\n","                i,\n","                skip_TNO,\n","            )\n","\n","    # Create meta_files for splits\n","    meta_data_dir = meta_data_dir\n","    if not os.path.exists(meta_data_dir):\n","        os.makedirs(meta_data_dir)\n","\n","    for i in splits:\n","        rttm_file = ref_rttm_dir + \"/fullref_ami_\" + i + \".rttm\"\n","        meta_filename_prefix = \"ami_\" + i\n","        prepare_metadata(\n","            rttm_file,\n","            meta_data_dir,\n","            data_folder,\n","            meta_filename_prefix,\n","            max_subseg_dur,\n","            overlap,\n","            mic_type,\n","        )\n","\n","    save_opt_file = os.path.join(save_folder, opt_file)\n","    save_pkl(conf, save_opt_file)\n","\n","\n","def get_RTTM_per_rec(segs, spkrs_list, rec_id):\n","    \"\"\"Prepares rttm for each recording\n","    \"\"\"\n","\n","    rttm = []\n","\n","    # Prepare header\n","    for spkr_id in spkrs_list:\n","        # e.g. SPKR-INFO ES2008c 0 <NA> <NA> <NA> unknown ES2008c.A_PM <NA> <NA>\n","        line = (\n","            \"SPKR-INFO \"\n","            + rec_id\n","            + \" 0 <NA> <NA> <NA> unknown \"\n","            + spkr_id\n","            + \" <NA> <NA>\"\n","        )\n","        rttm.append(line)\n","\n","    # Append remaining lines\n","    for row in segs:\n","        # e.g. SPEAKER ES2008c 0 37.880 0.590 <NA> <NA> ES2008c.A_PM <NA> <NA>\n","\n","        if float(row[1]) < float(row[0]):\n","            msg1 = (\n","                \"Possibly Incorrect Annotation Found!! transcriber_start (%s) > transcriber_end (%s)\"\n","                % (row[0], row[1])\n","            )\n","            msg2 = (\n","                \"Excluding this incorrect row from the RTTM : %s, %s, %s, %s\"\n","                % (\n","                    rec_id,\n","                    row[0],\n","                    str(round(float(row[1]) - float(row[0]), 4)),\n","                    str(row[2]),\n","                )\n","            )\n","            logger.info(msg1)\n","            logger.info(msg2)\n","            continue\n","\n","        line = (\n","            \"SPEAKER \"\n","            + rec_id\n","            + \" 0 \"\n","            + str(round(float(row[0]), 4))\n","            + \" \"\n","            + str(round(float(row[1]) - float(row[0]), 4))\n","            + \" <NA> <NA> \"\n","            + str(row[2])\n","            + \" <NA> <NA>\"\n","        )\n","        rttm.append(line)\n","\n","    return rttm\n","\n","\n","def prepare_segs_for_RTTM(\n","    list_ids, out_rttm_file, audio_dir, annot_dir, split_type, skip_TNO\n","):\n","\n","    RTTM = []  # Stores all RTTMs clubbed together for a given dataset split\n","\n","    for main_meet_id in list_ids:\n","\n","        # Skip TNO meetings from dev and eval sets\n","        if (\n","            main_meet_id.startswith(\"TS\")\n","            and split_type != \"train\"\n","            and skip_TNO is True\n","        ):\n","            msg = (\n","                \"Skipping TNO meeting in AMI \"\n","                + str(split_type)\n","                + \" set : \"\n","                + str(main_meet_id)\n","            )\n","            logger.info(msg)\n","            continue\n","\n","        list_sessions = glob.glob(audio_dir + \"/\" + main_meet_id + \"*\")\n","        list_sessions.sort()\n","\n","        for sess in list_sessions:\n","            rec_id = os.path.basename(sess)\n","            path = annot_dir + \"/segments/\" + rec_id\n","            f = path + \".*.segments.xml\"\n","            list_spkr_xmls = glob.glob(f)\n","            list_spkr_xmls.sort()  # A, B, C, D, E etc (Speakers)\n","            segs = []\n","            spkrs_list = (\n","                []\n","            )  # Since non-scenario recordings contains 3-5 speakers\n","\n","            for spkr_xml_file in list_spkr_xmls:\n","\n","                # Speaker ID\n","                spkr = os.path.basename(spkr_xml_file).split(\".\")[1]\n","                spkr_ID = rec_id + \".\" + spkr\n","                spkrs_list.append(spkr_ID)\n","\n","                # Parse xml tree\n","                tree = et.parse(spkr_xml_file)\n","                root = tree.getroot()\n","\n","                # Start, end and speaker_ID from xml file\n","                segs = segs + [\n","                    [\n","                        elem.attrib[\"transcriber_start\"],\n","                        elem.attrib[\"transcriber_end\"],\n","                        spkr_ID,\n","                    ]\n","                    for elem in root.iter(\"segment\")\n","                ]\n","\n","            # Sort rows as per the start time (per recording)\n","            segs.sort(key=lambda x: float(x[0]))\n","\n","            rttm_per_rec = get_RTTM_per_rec(segs, spkrs_list, rec_id)\n","            RTTM = RTTM + rttm_per_rec\n","\n","    # Write one RTTM as groundtruth. For example, \"fullref_eval.rttm\"\n","    with open(out_rttm_file, \"w\") as f:\n","        for item in RTTM:\n","            f.write(\"%s\\n\" % item)\n","\n","\n","def is_overlapped(end1, start2):\n","    \"\"\"Returns True if the two segments overlap\n","\n","    Arguments\n","    ---------\n","    end1 : float\n","        End time of the first segment.\n","    start2 : float\n","        Start time of the second segment.\n","    \"\"\"\n","\n","    if start2 > end1:\n","        return False\n","    else:\n","        return True\n","\n","\n","def merge_rttm_intervals(rttm_segs):\n","    \"\"\"Merges adjacent segments in rttm if they overlap.\n","    \"\"\"\n","    # For one recording\n","    # rec_id = rttm_segs[0][1]\n","    rttm_segs.sort(key=lambda x: float(x[3]))\n","\n","    # first_seg = rttm_segs[0] # first interval.. as it is\n","    merged_segs = [rttm_segs[0]]\n","    strt = float(rttm_segs[0][3])\n","    end = float(rttm_segs[0][3]) + float(rttm_segs[0][4])\n","\n","    for row in rttm_segs[1:]:\n","        s = float(row[3])\n","        e = float(row[3]) + float(row[4])\n","\n","        if is_overlapped(end, s):\n","            # Update only end. The strt will be same as in last segment\n","            # Just update last row in the merged_segs\n","            end = max(end, e)\n","            merged_segs[-1][3] = str(round(strt, 4))\n","            merged_segs[-1][4] = str(round((end - strt), 4))\n","            merged_segs[-1][7] = \"overlap\"  # previous_row[7] + '-'+ row[7]\n","        else:\n","            # Add a new disjoint segment\n","            strt = s\n","            end = e\n","            merged_segs.append(row)  # this will have 1 spkr ID\n","\n","    return merged_segs\n","\n","\n","def get_subsegments(merged_segs, max_subseg_dur=3.0, overlap=1.5):\n","    \"\"\"Divides bigger segments into smaller sub-segments\n","    \"\"\"\n","\n","    shift = max_subseg_dur - overlap\n","    subsegments = []\n","\n","    # These rows are in RTTM format\n","    for row in merged_segs:\n","        seg_dur = float(row[4])\n","        rec_id = row[1]\n","\n","        if seg_dur > max_subseg_dur:\n","            num_subsegs = int(seg_dur / shift)\n","            # Taking 0.01 sec as small step\n","            seg_start = float(row[3])\n","            seg_end = seg_start + seg_dur\n","\n","            # Now divide this segment (new_row) in smaller subsegments\n","            for i in range(num_subsegs):\n","                subseg_start = seg_start + i * shift\n","                subseg_end = min(subseg_start + max_subseg_dur - 0.01, seg_end)\n","                subseg_dur = subseg_end - subseg_start\n","\n","                new_row = [\n","                    \"SPEAKER\",\n","                    rec_id,\n","                    \"0\",\n","                    str(round(float(subseg_start), 4)),\n","                    str(round(float(subseg_dur), 4)),\n","                    \"<NA>\",\n","                    \"<NA>\",\n","                    row[7],\n","                    \"<NA>\",\n","                    \"<NA>\",\n","                ]\n","\n","                subsegments.append(new_row)\n","\n","                # Break if exceeding the boundary\n","                if subseg_end >= seg_end:\n","                    break\n","        else:\n","            subsegments.append(row)\n","\n","    return subsegments\n","\n","\n","def prepare_metadata(\n","    rttm_file, save_dir, data_dir, filename, max_subseg_dur, overlap, mic_type\n","):\n","    # Read RTTM, get unique meeting_IDs (from RTTM headers)\n","    # For each MeetingID. select that meetID -> merge -> subsegment -> json -> append\n","\n","    # Read RTTM\n","    RTTM = []\n","    with open(rttm_file, \"r\") as f:\n","        for line in f:\n","            entry = line[:-1]\n","            RTTM.append(entry)\n","\n","    spkr_info = filter(lambda x: x.startswith(\"SPKR-INFO\"), RTTM)\n","    rec_ids = list(set([row.split(\" \")[1] for row in spkr_info]))\n","    rec_ids.sort()  # sorting just to make JSON look in proper sequence\n","\n","    # For each recording merge segments and then perform subsegmentation\n","    MERGED_SEGMENTS = []\n","    SUBSEGMENTS = []\n","    for rec_id in rec_ids:\n","        segs_iter = filter(\n","            lambda x: x.startswith(\"SPEAKER \" + str(rec_id)), RTTM\n","        )\n","        gt_rttm_segs = [row.split(\" \") for row in segs_iter]\n","\n","        # Merge, subsegment and then convert to json format.\n","        merged_segs = merge_rttm_intervals(\n","            gt_rttm_segs\n","        )  # We lose speaker_ID after merging\n","        MERGED_SEGMENTS = MERGED_SEGMENTS + merged_segs\n","\n","        # Divide segments into smaller sub-segments\n","        subsegs = get_subsegments(merged_segs, max_subseg_dur, overlap)\n","        SUBSEGMENTS = SUBSEGMENTS + subsegs\n","\n","    # Write segment AND sub-segments (in RTTM format)\n","    segs_file = save_dir + \"/\" + filename + \".segments.rttm\"\n","    subsegment_file = save_dir + \"/\" + filename + \".subsegments.rttm\"\n","\n","    with open(segs_file, \"w\") as f:\n","        for row in MERGED_SEGMENTS:\n","            line_str = \" \".join(row)\n","            f.write(\"%s\\n\" % line_str)\n","\n","    with open(subsegment_file, \"w\") as f:\n","        for row in SUBSEGMENTS:\n","            line_str = \" \".join(row)\n","            f.write(\"%s\\n\" % line_str)\n","\n","    # Create JSON from subsegments\n","    json_dict = {}\n","    for row in SUBSEGMENTS:\n","        rec_id = row[1]\n","        strt = str(round(float(row[3]), 4))\n","        end = str(round((float(row[3]) + float(row[4])), 4))\n","        subsegment_ID = rec_id + \"_\" + strt + \"_\" + end\n","        dur = row[4]\n","        start_sample = int(float(strt) * SAMPLERATE)\n","        end_sample = int(float(end) * SAMPLERATE)\n","\n","        # If multi-mic audio is selected\n","        if mic_type == \"Array1\":\n","            wav_file_base_path = (\n","                data_dir\n","                + \"/\"\n","                + rec_id\n","                + \"/audio/\"\n","                + rec_id\n","                + \".\"\n","                + mic_type\n","                + \"-\"\n","            )\n","\n","            f = []  # adding all 8 mics\n","            for i in range(8):\n","                f.append(wav_file_base_path + str(i + 1).zfill(2) + \".wav\")\n","            audio_files_path_list = f\n","\n","            # Note: key \"files\" with 's' is used for multi-mic\n","            json_dict[subsegment_ID] = {\n","                \"wav\": {\n","                    \"files\": audio_files_path_list,\n","                    \"duration\": float(dur),\n","                    \"start\": int(start_sample),\n","                    \"stop\": int(end_sample),\n","                },\n","            }\n","        else:\n","            # Single mic audio\n","            wav_file_path = (\n","                data_dir\n","                + \"/\"\n","                + rec_id\n","                + \"/audio/\"\n","                + rec_id\n","                + \".\"\n","                + mic_type\n","                + \".wav\"\n","            )\n","\n","            # Note: key \"file\" without 's' is used for single-mic\n","            json_dict[subsegment_ID] = {\n","                \"wav\": {\n","                    \"file\": wav_file_path,\n","                    \"duration\": float(dur),\n","                    \"start\": int(start_sample),\n","                    \"stop\": int(end_sample),\n","                },\n","            }\n","\n","    out_json_file = save_dir + \"/\" + filename + \".\" + mic_type + \".subsegs.json\"\n","    with open(out_json_file, mode=\"w\") as json_f:\n","        json.dump(json_dict, json_f, indent=2)\n","\n","    msg = \"%s JSON prepared\" % (out_json_file)\n","    logger.debug(msg)\n","\n","\n","def skip(save_folder, conf, meta_files, opt_file):\n","    \"\"\"\n","    Detects if the AMI data_preparation has been already done.\n","    If the preparation has been done, we can skip it.\n","\n","    Returns\n","    -------\n","    bool\n","        if True, the preparation phase can be skipped.\n","        if False, it must be done.\n","    \"\"\"\n","    # Checking if meta (json) files are available\n","    skip = True\n","    for file_path in meta_files:\n","        if not os.path.isfile(file_path):\n","            skip = False\n","\n","    # Checking saved options\n","    save_opt_file = os.path.join(save_folder, opt_file)\n","    if skip is True:\n","        if os.path.isfile(save_opt_file):\n","            opts_old = load_pkl(save_opt_file)\n","            if opts_old == conf:\n","                skip = True\n","            else:\n","                skip = False\n","        else:\n","            skip = False\n","\n","    return skip"]}]}